<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on Hervé Kakiang&#39;s blog</title>
    <link>https://hrv2k.github.io/categories/machine-learning/</link>
    <description>Recent content in Machine Learning on Hervé Kakiang&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>Copyright © 20019–2021, Hervé Kakiang; all rights reserved.</copyright>
    <lastBuildDate>Wed, 09 Dec 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://hrv2k.github.io/categories/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Hello, Machine Learning</title>
      <link>https://hrv2k.github.io/post/what-is-machine-learning/</link>
      <pubDate>Wed, 09 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hrv2k.github.io/post/what-is-machine-learning/</guid>
      <description>
        
          &lt;h2 id=&#34;1-a-brief-history-of-machine-learning&#34;&gt;1. A brief history of Machine Learning&lt;/h2&gt;
&lt;p&gt;Scientists have long dreamed of building machines that would be able to perfectly simulate the cognitive faculties of the human mind and doing so free of human interference. It all started in 1842 with Lady Lovelace, the world’s first programmer who wrote programs about 100 years before there were computers to run them, when asked whether computers could get really smart. she responded by saying, &amp;quot;The Analytical Engine has no pretensions to originate anything. It can do whatever we know how to order it to perform&amp;quot;.&lt;/p&gt;
&lt;p&gt;Since the first programmables computers, AI researchers have attempted not just to understand how humans think in order to replicate it but also to build intelligent agents. Before the 1980s, AI research was divided between what is called “strong AI” and “weak AI”. “Strong AI” referred to AI that could generally perform any intellectual task that a human could, whereas “weak AI”, also called functional or narrow AI, referred to the applications of AI techniques to solve practical problems.&lt;/p&gt;
&lt;p&gt;In order to behave in a way that humans do, AI systems need to acquire the large amount of knowledge that humans have. A machine that could exhibit a human-like intelligence, an AI agent per se, would need to possess the following capabilities: knowledge representations, automated reasoning, machine learning, representations of vision and language and robotics (Luger, 2008; Russell &amp;amp; Norvig, 2009). At its minimum, an AI agent should be capable of learning, processing and understanding visual and linguistic data, reasoning and performing motor movements. Many AI projects have had the goal to incorporate knowledge about the world by devising a database of formal rules written by human experts that supposedly describe the world. An example of such a project is Cyc (Lenat &amp;amp; Guha, 1989). This approach known as knowledge base approach has not led to major success in the AI field. In the case of the Cyc project, the system was told a story of a person named Fred shaving with an electrical razor, it detected an inconsistency in the story because it wasn’t sure whether Fred had electrical parts or not. Then it asked if Fred while shaving was still a person. This difficulty demonstrates the necessity for AI systems to have the ability to extract knowledge about the world from raw data themselves without being explicitly told what to infer in every situation. This is called Machine Learning.&lt;/p&gt;
&lt;p&gt;The origins of machine learning can be traced back to 1943, when McCulloch and Pitts (1943) introduced the first artificial neuron. They showed that networks of these neurons could, in principle, compute any arithmetic or logical function. As no training method was available, the parameters of their networks had to be designed. However, the perceived connection between biology and digital computers generated a great deal of interest. In 1950 Alan Turing, an English mathematician who had previously won the Second World War by breaking the German code, wrote his famous paper, Computing Machinery and Intelligence, in which he introduced the Turing test. The Turing test is a test of a machine’s ability to exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human. To pass the test, a computer must be able to fool a human into believing it is also human. Around the same time in 1952, Arthur Samuel wrote the first computer learning program. The program was a game of checkers, and the IBM computer improved at the game the more it played, studying which moves made up winning strategies in a “supervised learning mode”and incorporating those moves into its program. Rosenblatt (1958) developed a class of neural networks called perceptrons (single-layer neural networks). The neurons in these networks were similar to those of McCulloch and Pitts (1943). More than that, Rosenblatt (1958) introduced a learning rule for training perceptron networks to solve classification problems. Given an input feature vector, the perceptron algorithm could learn to classify inputs as belonging to a specific class. Using a training set, the network’s weights and bias could be updated for linear classification. As a linear classifier the perceptron was limited. It was demonstrated in 1969 that the perceptron was incapable of learning certain elementary functions such as the XOR function. Those problems are not linearly solvable (Minsky &amp;amp; Papert, 1969). The limitations of the perceptrons were overcome by the conception of a Multilayer Perceptron (Werbos, 1981). It makes used of Backpropagation (BP) algorithm for learning. Around the 1980s, machine learning became a prominent area of research.&lt;/p&gt;
&lt;p&gt;In the 1990s, the intersection of computer science and statistics gave birth to probabilistic approaches in machine learning, causing the field to shift from a knowledge-driven approach to a data-driven approach. Having large-scale data available, scientists started to build intelligent systems that were able to analyze and learn from large amounts of data. As an example, IBM’s Deep Blue system beat the world champion of chess, the grand master Garry Kasparov in 1997. In 1995, Corinna and Vapnik (1995) published their work on SVM. SVM is a discriminative classifier formally defined by a separating hyperplane. The idea behind is to map input data to a high-dimension feature space and then construct a linear decision plane in that feature space. It performs by finding the optimal separating hyperlane, that is the hyperplane that maximizes the margin of the training data. SVM have had many empirical successes in many pattern recognition applications such as handwriting recognition (Corinna &amp;amp; Vapnik, 1995), text classification (Joachims, 1998) and image retrieval (Tong &amp;amp; Chang, 2001).&lt;/p&gt;
&lt;p&gt;Around the year 2000 deep learning emerged. Deep learning is a machine learning method that uses neural networks with many layers deep. This evolution of neural networks has successfully solved complex problems in various domains. The Google Brain team creates a neural networks system that learns to recognize high-level concepts namely cats and faces in images taken from frames of YouTube videos with no supervisory signals given to the neurons during training (Le et al., 2012).&lt;/p&gt;
&lt;p&gt;In 2016, Google’s AlphaGo program becomes the first computer program to beat an unhandicapped professional human player using a combination of deep neural networks and tree search techniques. AlphaGo was improved to become AlphaGo Zero and then in 2017 generalized to Chess and more two-player games as AlphaZero.&lt;/p&gt;
&lt;h2 id=&#34;2-what-is-machine-learning&#34;&gt;2. What Is Machine Learning&lt;/h2&gt;
&lt;p&gt;Back in 1959, Arthur Samuel described Machine Learning (ML) as the “Field of study that gives computers the ability to learn without being explicitly programmed”. ML algorithms mimic the human’s ability to learn from experience. They generate models based on the data (experience) that they receive as input. They adaptively improve the model performance as the amount of data available for the learning process increases.&lt;/p&gt;
&lt;p&gt;Today, there are many applications of ML algorithms to practical problems. That is because models created by machine learning algorithms for problems such as spam filtering, speech, image and object recognition, language translation, text understanding, targeted advertisement, recommender system, medical diagnosis, etc. have many advantages over code written by human developers. Especially image recognition ML models are giving amazing results.&lt;/p&gt;
&lt;p&gt;Usually to solve a problem using computer, we build an algorithm. An algorithm is a sequence of instructions that should be carried out to solve a problem. An algorithm takes an input, processes it and ouputs a result. A particular problem may be solvable by various algorithms. However, in general we are interested in finding the most efficient algorithm that requires the least amount of time or memory or both to compute. The paradigm is different when using ML approach. Instead of creating step-by-step instructions to solve problems as it is usually done in traditional programming, this task is outsourced to an ML algorithm. The ML algorithm is fed input data and outputs expected once the inputs are processed. Based on these sets of data, a function or model is induced by the learning algorithm. The resulting model is a function that maps from the input space (this sapce contains the input data) to the output space (this sapce contains the output data). We say the ML algorithm has trained a model; and the model has learned from data. The model built represents the computer program.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hrv2k.github.io/images/tpvsml.jpg&#34; alt=&#34;TP vs ML&#34;&gt;&lt;/p&gt;
&lt;p&gt;But how exactly does a computer program learn? Mitchell (1997) explained that, “A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.”&lt;/p&gt;
&lt;p&gt;OK, but what does that even mean? To illustrate let’s use a particular example. In 1959, Samuel wrote a program that played checkers games against itself. The program learned to recognize patterns that led to win and those that led to loss. Over a period of about 10 hours of training, the program was able to play checkers much better than human player. This learning problem can be specified as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Task T: Playing checkers&lt;/li&gt;
&lt;li&gt;Performance measure P: Percentage of games won against opponents&lt;/li&gt;
&lt;li&gt;Experience E: Playing games against itself.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Samuel&#39;s program improved the percentage of games won against its opponents at playing checkers through experience gained by playing the game against itself. By Mitchell’s definition, Samuel’s checkers program has learned to play checkers.&lt;/p&gt;
&lt;p&gt;The class of tasks T, the measure of performance to be improved P, and the source of experience E, are the three elements of a well-defined learning problem.&lt;/p&gt;
&lt;h2 id=&#34;3-learning-problem&#34;&gt;3. Learning problem&lt;/h2&gt;
&lt;h3 id=&#34;task-t&#34;&gt;Task T&lt;/h3&gt;
&lt;p&gt;Learning tasks are inumerable and diverse. Usually these tasks are too difficult or complex to be solved with hardcoded programs designed by software developers. For example, if we want to make a car able to drive itself in higways using  a sequence of images capture by cameras mounted on the car, steering commands recorded while observing a human driver and other sensors input, then &amp;quot;driving in highways&amp;quot; is the learning task.
Based on the desired output of the learning system, various kind of tasks can be tackled using machine learning.&lt;/p&gt;
&lt;p&gt;Classification task is the type of task where a learning algorithm is asked to output a category y to which a certain input x belongs.&lt;/p&gt;
&lt;p&gt;Regression task is the type of task for which the goal is to predict a continuous value given some input.&lt;/p&gt;
&lt;p&gt;Clustering task, the program is asked to assign a set of observations to groups called clusters so that observations within the same cluster are similar according to some criteria, while observations drawn from different clusters are dissimilar.  Basically clustering algorithms discover patterns, regularities (correlations) in sets of data.&lt;/p&gt;
&lt;p&gt;These are also generic learning tasks that we often encounter.&lt;/p&gt;
&lt;h3 id=&#34;performance-measure-p&#34;&gt;Performance measure P&lt;/h3&gt;
&lt;p&gt;During the learning process we need to assess the capabilities of the learning system with respect to the learning task. A performance measure is used to do that. The performance measure P is a quantitative metric or set of metrics that measures how good or accurate the patterns leant from data are. In case of classificaton tasks for example, the performance measure is accuracy, that is the proportion of input examples (or observations) for which the output produced by the learning system and the actual output match up. In the example of the self-driving car, the performance measure may be the average distance travelled by the car before an error occured. The performance measure allows us to evaluate the abilities of the program with respect to the task being performed.&lt;/p&gt;
&lt;h3 id=&#34;experience-e&#34;&gt;Experience E&lt;/h3&gt;
&lt;p&gt;The training experience E is what allows machine learning algorithms to learn. The training experience refers to the data from which the learning algorithm extract patterns, regularities or correlations. For the self-driving car example, the training examples may be a sequence of images, video clips, steering commands and breaking commands, etc. recorded while observing a human driver. The training experience for a spam filter learning system for example is usually a list of emails labelled as “spam” and emails labeled as “not spam”.&lt;/p&gt;
&lt;h2 id=&#34;4-types-of-machine-learning-tasks&#34;&gt;4. Types of Machine Learning Tasks&lt;/h2&gt;
&lt;p&gt;We can classify Machine Learning (ML) tasks into three broad categories based on the type of experience (i.e., training data) used to train ML models: Supervised Learning, Reinforcement Learning and Unsupervised Learning.
An ML model is what an ML algorithm outputs after the learning process. In other words it is the representation of what an ML system has learned from the training data.&lt;/p&gt;
&lt;h3 id=&#34;supervised-learning&#34;&gt;Supervised Learning&lt;/h3&gt;
&lt;p&gt;Supervised learning refers to the type of learning whereby an ML model is built using labelled examples. The learning process is guided. That is, for each training example the correct answer is known and used during the training process.  The learning algorithm analyzes the training examples, each example consisting of an input object, typically a vector, and the correct output value to infer a function that maps from the inputs to the outputs. The training process is said in this type of learning to be guided because for every instance object in the training data, the correct label is available to the algorithm. This type of machine learning is a bit analogous to how students study for exams. They study a bunch of questions and their correct answers. That’s the mapping from inputs to outputs. Then at the exam, they are asked unseen questions (questions that weren’t encountered when they were studying) and are expected to provide correct answers.&lt;/p&gt;
&lt;p&gt;So for an example that wasn’t used in the training as input to the learnt function, the output is expected to be the correct output.  An optimal scenario will allow for the  inferred function or ML model to correctly determine the output of unknown input examples. This is called generalization. The ability for an ML model to produce correct outputs for inputs that weren’t encountered during learning.&lt;/p&gt;
&lt;p&gt;The term supervised refers to the kind of experience that the algorithm is allowed to have during the training process. Each example is associated with a label. The correct output signal of each example is known in advance and used for training.&lt;/p&gt;
&lt;h3 id=&#34;unsupervised-learning&#34;&gt;Unsupervised Learning&lt;/h3&gt;
&lt;p&gt;With supervised learning, the correct output is known beforehand, whereas with unsupervised learning, the output is not known and the learning algorithm tries to identify commonalities and patterns between the inputs so that inputs that have something in common are categorized together. The training examples are unlabelled and the goal of unpervised learning algorithms are to train ML models that will find structures embedded or hidden in a dataset with no “guidance”.
The most common unsupervised learning task is clustering. Unsupervised learning is even sometimes referred to as cluster analysis, however it’s just an element of unsupervised ML. With cluster analysis, given a set of unlabelled examples, the goal is to classify or categorize data into clusters so that data within the same cluster are similar according to some criteria identified by the learning system, while data drawn from different clusters are dissimilar.  Basically the most common use of unsupervised machine learning is to discover patterns, regularities or correlations in unlabelled data sets.&lt;/p&gt;
&lt;h3 id=&#34;reinforcement-learning&#34;&gt;Reinforcement Learning&lt;/h3&gt;
&lt;p&gt;Another type of machine learning is reinforcement learning. With reinforcement learning, the goal is to develop an agent that improves its performance based on the interactions that it has with its environment. The agent is the learner (a robot, for example), and the environment is where it is learning (a room crowded with chairs), and what it is learning about (walking while avoiding obstacles, for example).&lt;/p&gt;
&lt;p&gt;The performance of the agent is quantified through some reward function. For the example of a robot learning to walk while avoiding obstacles, the reward could be how well it walks without crashing into chairs.  The reward for particular actions taken by the agent is defined behore the training. That gives the reinforment learning approach a touch of supervised learning. However, this feedback formalized by the reward function is not the ground truth or label as it is the case with supervised learning. But it’s a measure of how well the action taken by the agent was as measured by the reward function. The correct answer remains unknown to the agent, giving an unsupervised flavour to the reinforcement learning approach. So reinforcement learning is somewhere between supervised and unsupervised learning.  In the instance of our robot learner, he is not taught how to walk while avoiding chairs, but he is rewarded negatively (punish) when he crashes into chairs and rewarded positively when he manages to avoid an obstacle.
Through interactions with the environment and via an exploratory sequence of trial-and-error approach, an agent can learn a series of actions that maximizes its reward. In other words, the agent has to try out different possibilities and figure out which work best based on the reward that he gets.&lt;/p&gt;

        
      </description>
    </item>
    
  </channel>
</rss>
